[START]
2019-12-06-21-59-59
==============================
HRED (
  (goal_encoder): MlpGoalEncoder(
    (cnt_enc): Embedding(12, 64)
    (val_enc): Embedding(12, 64)
    (encoder): Sequential(
      (0): Tanh()
      (1): Linear(in_features=192, out_features=64, bias=True)
    )
  ), parameters=13888
  (embedding): Embedding(2542, 256, padding_idx=0), parameters=650752
  (utt_encoder): RnnUttEncoder(
    (embedding): Embedding(2542, 256, padding_idx=0)
    (rnn): EncoderRNN(
      (input_dropout): Dropout(p=0.3, inplace=False)
      (rnn): GRU(321, 128, batch_first=True, dropout=0.3, bidirectional=True)
    )
  ), parameters=997120
  (ctx_encoder): EncoderRNN(
    (input_dropout): Dropout(p=0.0, inplace=False)
    (rnn): GRU(256, 256, batch_first=True, dropout=0.3)
  ), parameters=394752
  (connector): IdentityConnector(), parameters=0
  (decoder): DecoderRNN(
    (input_dropout): Dropout(p=0.3, inplace=False)
    (rnn): GRU(320, 256, batch_first=True, dropout=0.3)
    (embedding): Embedding(2542, 256, padding_idx=0)
    (project): Linear(in_features=256, out_features=2542, bias=True)
  ), parameters=1747950
  (nll): NLLEntropy(), parameters=0
  (book_emb): Embedding(16, 32), parameters=512
  (hat_emb): Embedding(16, 32), parameters=512
  (ball_emb): Embedding(16, 32), parameters=512
  (res_layer): ResidualLayer(
    (lin1): Linear(in_features=96, out_features=64, bias=True)
    (lin2): Linear(in_features=64, out_features=64, bias=True)
    (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  ), parameters=10496
  (w_pz0): Linear(in_features=64, out_features=64, bias=False), parameters=4096
  (prior_res_layer): ResidualLayer(
    (lin1): Linear(in_features=256, out_features=64, bias=True)
    (lin2): Linear(in_features=64, out_features=64, bias=True)
    (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  ), parameters=20736
  (res_goal_mlp): ResidualLayer(
    (lin1): Linear(in_features=192, out_features=64, bias=True)
    (lin2): Linear(in_features=64, out_features=64, bias=True)
    (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  ), parameters=16640
) Total Parameters=3857966
***** Training Begins at 2019-12-06 22-00-28 *****
***** Epoch 0/50 *****
100/400-(0.000): Train nll PPL 31.636
200/400-(0.000): Train nll PPL 12.521
300/400-(0.000): Train nll PPL 9.421
0/400-(0.000): Train nll PPL 8.869
Checkpoint step at 2019-12-06 22-00-34
==== Evaluating Model ====
Train nll PPL 13.488
done epoch 0 -> 1
Generation: 50 batches
Val nll PPL 8.378
Total valid loss = 2.1255939600652436
Test nll PPL 8.035
Total valid loss = 2.083823874422806
Update patience to 10
!!Model Saved with loss = 2.1255939600652436,at 2019-12-06 22-00-38.

***** Epoch 1/50 *****
100/400-(0.000): Train nll PPL 9.238
200/400-(0.000): Train nll PPL 8.162
300/400-(0.000): Train nll PPL 7.967
0/400-(0.000): Train nll PPL 7.600
Checkpoint step at 2019-12-06 22-00-46
==== Evaluating Model ====
Train nll PPL 8.220
done epoch 1 -> 2
Generation: 50 batches
Val nll PPL 7.031
Total valid loss = 1.9503355021846251
Test nll PPL 6.797
Total valid loss = 1.916497963236312
Update patience to 10
!!Model Saved with loss = 1.9503355021846251,at 2019-12-06 22-00-50.

***** Epoch 2/50 *****
100/400-(0.000): Train nll PPL 7.264
200/400-(0.000): Train nll PPL 7.468
300/400-(0.000): Train nll PPL 7.506
0/400-(0.000): Train nll PPL 6.667
Checkpoint step at 2019-12-06 22-00-56
==== Evaluating Model ====
Train nll PPL 7.218
done epoch 2 -> 3
Generation: 50 batches
Val nll PPL 6.222
Total valid loss = 1.8281577937717368
Test nll PPL 6.025
Total valid loss = 1.7958758398607204
Update patience to 10
!!Model Saved with loss = 1.8281577937717368,at 2019-12-06 22-01-01.

***** Epoch 3/50 *****
100/400-(0.000): Train nll PPL 6.850
200/400-(0.000): Train nll PPL 6.772
300/400-(0.000): Train nll PPL 6.335
0/400-(0.000): Train nll PPL 6.403
Checkpoint step at 2019-12-06 22-01-07
==== Evaluating Model ====
Train nll PPL 6.586
done epoch 3 -> 4
Generation: 50 batches
Val nll PPL 5.971
Total valid loss = 1.7868643737367158
Test nll PPL 5.699
Total valid loss = 1.7402710651716806
Update patience to 10
!!Model Saved with loss = 1.7868643737367158,at 2019-12-06 22-01-11.

***** Epoch 4/50 *****
100/400-(0.000): Train nll PPL 6.427
200/400-(0.000): Train nll PPL 5.994
300/400-(0.000): Train nll PPL 6.474
0/400-(0.000): Train nll PPL 5.828
Checkpoint step at 2019-12-06 22-01-17
==== Evaluating Model ====
Train nll PPL 6.174
done epoch 4 -> 5
Generation: 50 batches
Val nll PPL 5.804
Total valid loss = 1.7584817438108016
Test nll PPL 5.567
Total valid loss = 1.7167918457731095
Update patience to 10
!!Model Saved with loss = 1.7584817438108016,at 2019-12-06 22-01-21.

***** Epoch 5/50 *****
100/400-(0.000): Train nll PPL 5.889
200/400-(0.000): Train nll PPL 5.994
300/400-(0.000): Train nll PPL 5.854
0/400-(0.000): Train nll PPL 5.787
Checkpoint step at 2019-12-06 22-01-28
==== Evaluating Model ====
Train nll PPL 5.881
done epoch 5 -> 6
Generation: 50 batches
Val nll PPL 5.431
Total valid loss = 1.6920757135341968
Test nll PPL 5.266
Total valid loss = 1.661270061599891
Update patience to 12.0
!!Model Saved with loss = 1.6920757135341968,at 2019-12-06 22-01-32.

***** Epoch 6/50 *****
100/400-(0.000): Train nll PPL 5.569
200/400-(0.000): Train nll PPL 5.330
300/400-(0.000): Train nll PPL 4.882
0/400-(0.000): Train nll PPL 5.403
Checkpoint step at 2019-12-06 22-01-38
==== Evaluating Model ====
Train nll PPL 5.290
done epoch 6 -> 7
Generation: 50 batches
Val nll PPL 5.269
Total valid loss = 1.6619119531993936
Test nll PPL 5.097
Total valid loss = 1.6286131303346656
Update patience to 14.0
!!Model Saved with loss = 1.6619119531993936,at 2019-12-06 22-01-42.

***** Epoch 7/50 *****
100/400-(0.000): Train nll PPL 5.172
200/400-(0.000): Train nll PPL 5.260
300/400-(0.000): Train nll PPL 5.470
0/400-(0.000): Train nll PPL 4.769
Checkpoint step at 2019-12-06 22-01-48
==== Evaluating Model ====
Train nll PPL 5.162
done epoch 7 -> 8
Generation: 50 batches
Val nll PPL 5.108
Total valid loss = 1.6307130205235358
Test nll PPL 4.973
Total valid loss = 1.6039709337763912
Update patience to 16.0
!!Model Saved with loss = 1.6307130205235358,at 2019-12-06 22-01-52.

***** Epoch 8/50 *****
100/400-(0.000): Train nll PPL 5.131
200/400-(0.000): Train nll PPL 5.323
300/400-(0.000): Train nll PPL 5.127
0/400-(0.000): Train nll PPL 5.192
Checkpoint step at 2019-12-06 22-01-59
==== Evaluating Model ====
Train nll PPL 5.193
done epoch 8 -> 9
Generation: 50 batches
Val nll PPL 5.031
Total valid loss = 1.6156963637834105
Test nll PPL 4.854
Total valid loss = 1.5798451730506955
Update patience to 18.0
!!Model Saved with loss = 1.6156963637834105,at 2019-12-06 22-02-03.

***** Epoch 9/50 *****
100/400-(0.000): Train nll PPL 4.801
200/400-(0.000): Train nll PPL 5.039
300/400-(0.000): Train nll PPL 4.641
0/400-(0.000): Train nll PPL 5.136
Checkpoint step at 2019-12-06 22-02-09
==== Evaluating Model ====
Train nll PPL 4.901
done epoch 9 -> 10
Generation: 50 batches
Val nll PPL 4.985
Total valid loss = 1.6064228916960008
Test nll PPL 4.795
Total valid loss = 1.5674871326399393
Update patience to 20.0
!!Model Saved with loss = 1.6064228916960008,at 2019-12-06 22-02-13.

***** Epoch 10/50 *****
100/400-(0.000): Train nll PPL 5.313
200/400-(0.000): Train nll PPL 5.120
300/400-(0.000): Train nll PPL 5.306
0/400-(0.000): Train nll PPL 5.009
Checkpoint step at 2019-12-06 22-02-19
==== Evaluating Model ====
Train nll PPL 5.185
done epoch 10 -> 11
Generation: 50 batches
Val nll PPL 4.922
Total valid loss = 1.5937479400106902
Test nll PPL 4.709
Total valid loss = 1.5494512401152927
Update patience to 22.0
!!Model Saved with loss = 1.5937479400106902,at 2019-12-06 22-02-24.

***** Epoch 11/50 *****
100/400-(0.000): Train nll PPL 5.281
200/400-(0.000): Train nll PPL 5.163
300/400-(0.000): Train nll PPL 5.178
0/400-(0.000): Train nll PPL 5.250
Checkpoint step at 2019-12-06 22-02-30
==== Evaluating Model ====
Train nll PPL 5.218
done epoch 11 -> 12
Generation: 50 batches
Val nll PPL 4.789
Total valid loss = 1.5663574333560424
Test nll PPL 4.674
Total valid loss = 1.5419279378856543
Update patience to 24.0
!!Model Saved with loss = 1.5663574333560424,at 2019-12-06 22-02-34.

***** Epoch 12/50 *****
100/400-(0.000): Train nll PPL 5.156
200/400-(0.000): Train nll PPL 4.990
300/400-(0.000): Train nll PPL 4.596
0/400-(0.000): Train nll PPL 4.883
Checkpoint step at 2019-12-06 22-02-41
==== Evaluating Model ====
Train nll PPL 4.902
done epoch 12 -> 13
Generation: 50 batches
Val nll PPL 4.753
Total valid loss = 1.5587004986196427
Test nll PPL 4.585
Total valid loss = 1.5228932218859856
Update patience to 26.0
!!Model Saved with loss = 1.5587004986196427,at 2019-12-06 22-02-45.

***** Epoch 13/50 *****
100/400-(0.000): Train nll PPL 4.481
200/400-(0.000): Train nll PPL 4.567
300/400-(0.000): Train nll PPL 4.248
0/400-(0.000): Train nll PPL 4.749
Checkpoint step at 2019-12-06 22-02-52
==== Evaluating Model ====
Train nll PPL 4.508
done epoch 13 -> 14
Generation: 50 batches
Val nll PPL 4.684
Total valid loss = 1.544164309202525
Test nll PPL 4.551
Total valid loss = 1.5153217213688694
Update patience to 28.0
!!Model Saved with loss = 1.544164309202525,at 2019-12-06 22-02-56.

***** Epoch 14/50 *****
100/400-(0.000): Train nll PPL 4.678
200/400-(0.000): Train nll PPL 4.617
300/400-(0.000): Train nll PPL 4.330
0/400-(0.000): Train nll PPL 4.305
Checkpoint step at 2019-12-06 22-03-02
==== Evaluating Model ====
Train nll PPL 4.479
done epoch 14 -> 15
Generation: 50 batches
Val nll PPL 4.736
Total valid loss = 1.5552113689619678
Test nll PPL 4.555
Total valid loss = 1.5162227983257164

***** Epoch 15/50 *****
100/400-(0.000): Train nll PPL 4.510
200/400-(0.000): Train nll PPL 4.667
300/400-(0.000): Train nll PPL 4.538
0/400-(0.000): Train nll PPL 4.687
Checkpoint step at 2019-12-06 22-03-13
==== Evaluating Model ====
Train nll PPL 4.600
done epoch 15 -> 16
Generation: 50 batches
Val nll PPL 4.661
Total valid loss = 1.5393366721283466
Test nll PPL 4.517
Total valid loss = 1.5077975043325824
!!Model Saved with loss = 1.5393366721283466,at 2019-12-06 22-03-17.

***** Epoch 16/50 *****
100/400-(0.000): Train nll PPL 4.330
200/400-(0.000): Train nll PPL 4.735
300/400-(0.000): Train nll PPL 4.472
0/400-(0.000): Train nll PPL 4.552
Checkpoint step at 2019-12-06 22-03-24
==== Evaluating Model ====
Train nll PPL 4.519
done epoch 16 -> 17
Generation: 50 batches
Val nll PPL 4.568
Total valid loss = 1.5190076583865824
Test nll PPL 4.436
Total valid loss = 1.4896500965035007
Update patience to 34.0
!!Model Saved with loss = 1.5190076583865824,at 2019-12-06 22-03-28.

***** Epoch 17/50 *****
100/400-(0.000): Train nll PPL 4.763
200/400-(0.000): Train nll PPL 4.371
300/400-(0.000): Train nll PPL 4.564
0/400-(0.000): Train nll PPL 4.725
Checkpoint step at 2019-12-06 22-03-34
==== Evaluating Model ====
Train nll PPL 4.603
done epoch 17 -> 18
Generation: 50 batches
Val nll PPL 4.671
Total valid loss = 1.5413568384972887
Test nll PPL 4.529
Total valid loss = 1.5103990419735926

***** Epoch 18/50 *****
100/400-(0.000): Train nll PPL 4.669
200/400-(0.000): Train nll PPL 4.819
300/400-(0.000): Train nll PPL 4.281
0/400-(0.000): Train nll PPL 4.353
Checkpoint step at 2019-12-06 22-03-45
==== Evaluating Model ====
Train nll PPL 4.525
done epoch 18 -> 19
Generation: 50 batches
Val nll PPL 4.563
Total valid loss = 1.517956166469743
Test nll PPL 4.387
Total valid loss = 1.4787370280394536
!!Model Saved with loss = 1.517956166469743,at 2019-12-06 22-03-49.

***** Epoch 19/50 *****
100/400-(0.000): Train nll PPL 4.043
200/400-(0.000): Train nll PPL 4.248
300/400-(0.000): Train nll PPL 4.264
0/400-(0.000): Train nll PPL 4.331
Checkpoint step at 2019-12-06 22-03-55
==== Evaluating Model ====
Train nll PPL 4.220
done epoch 19 -> 20
Generation: 50 batches
Val nll PPL 4.532
Total valid loss = 1.511186782724303
Test nll PPL 4.390
Total valid loss = 1.479241116191951
Update patience to 40.0
!!Model Saved with loss = 1.511186782724303,at 2019-12-06 22-03-59.

***** Epoch 20/50 *****
100/400-(0.000): Train nll PPL 4.344
200/400-(0.000): Train nll PPL 4.290
300/400-(0.000): Train nll PPL 4.012
0/400-(0.000): Train nll PPL 4.019
Checkpoint step at 2019-12-06 22-04-06
==== Evaluating Model ====
Train nll PPL 4.163
done epoch 20 -> 21
Generation: 50 batches
Val nll PPL 4.517
Total valid loss = 1.5077751061133353
Test nll PPL 4.387
Total valid loss = 1.4785557688415731
!!Model Saved with loss = 1.5077751061133353,at 2019-12-06 22-04-10.

***** Epoch 21/50 *****
100/400-(0.000): Train nll PPL 3.923
200/400-(0.000): Train nll PPL 4.375
300/400-(0.000): Train nll PPL 4.376
0/400-(0.000): Train nll PPL 4.222
Checkpoint step at 2019-12-06 22-04-16
==== Evaluating Model ====
Train nll PPL 4.220
done epoch 21 -> 22
Generation: 50 batches
Val nll PPL 4.506
Total valid loss = 1.5054567711379696
Test nll PPL 4.365
Total valid loss = 1.4736868877374627
!!Model Saved with loss = 1.5054567711379696,at 2019-12-06 22-04-20.

***** Epoch 22/50 *****
100/400-(0.000): Train nll PPL 4.564
200/400-(0.000): Train nll PPL 3.970
300/400-(0.000): Train nll PPL 4.082
0/400-(0.000): Train nll PPL 4.439
Checkpoint step at 2019-12-06 22-04-27
==== Evaluating Model ====
Train nll PPL 4.257
done epoch 22 -> 23
Generation: 50 batches
Val nll PPL 4.476
Total valid loss = 1.498790974766566
Test nll PPL 4.352
Total valid loss = 1.470631686793534
Update patience to 46.0
!!Model Saved with loss = 1.498790974766566,at 2019-12-06 22-04-31.

***** Epoch 23/50 *****
100/400-(0.000): Train nll PPL 4.530
200/400-(0.000): Train nll PPL 4.218
300/400-(0.000): Train nll PPL 4.381
0/400-(0.000): Train nll PPL 4.276
Checkpoint step at 2019-12-06 22-04-37
==== Evaluating Model ====
Train nll PPL 4.350
done epoch 23 -> 24
Generation: 50 batches
Val nll PPL 4.544
Total valid loss = 1.5138398938953217
Test nll PPL 4.412
Total valid loss = 1.484311847405742

***** Epoch 24/50 *****
100/400-(0.000): Train nll PPL 4.216
200/400-(0.000): Train nll PPL 4.408
300/400-(0.000): Train nll PPL 4.164
0/400-(0.000): Train nll PPL 4.087
Checkpoint step at 2019-12-06 22-04-47
==== Evaluating Model ====
Train nll PPL 4.217
done epoch 24 -> 25
Generation: 50 batches
Val nll PPL 4.460
Total valid loss = 1.495056440029637
Test nll PPL 4.335
Total valid loss = 1.4667163117303594
!!Model Saved with loss = 1.495056440029637,at 2019-12-06 22-04-51.

***** Epoch 25/50 *****
100/400-(0.000): Train nll PPL 4.149
200/400-(0.000): Train nll PPL 3.762
300/400-(0.000): Train nll PPL 3.901
0/400-(0.000): Train nll PPL 3.653
Checkpoint step at 2019-12-06 22-04-58
==== Evaluating Model ====
Train nll PPL 3.862
done epoch 25 -> 26
Generation: 50 batches
Val nll PPL 4.480
Total valid loss = 1.4995359785002536
Test nll PPL 4.377
Total valid loss = 1.4764401885493172

***** Epoch 26/50 *****
100/400-(0.000): Train nll PPL 3.700
200/400-(0.000): Train nll PPL 4.066
300/400-(0.000): Train nll PPL 4.346
0/400-(0.000): Train nll PPL 3.904
Checkpoint step at 2019-12-06 22-05-08
==== Evaluating Model ====
Train nll PPL 3.997
done epoch 26 -> 27
Generation: 50 batches
Val nll PPL 4.520
Total valid loss = 1.508496441524407
Test nll PPL 4.336
Total valid loss = 1.4668482075172686

***** Epoch 27/50 *****
100/400-(0.000): Train nll PPL 4.041
200/400-(0.000): Train nll PPL 3.882
300/400-(0.000): Train nll PPL 3.884
0/400-(0.000): Train nll PPL 3.802
Checkpoint step at 2019-12-06 22-05-18
==== Evaluating Model ====
Train nll PPL 3.901
done epoch 27 -> 28
Generation: 50 batches
Val nll PPL 4.353
Total valid loss = 1.470967296304738
Test nll PPL 4.202
Total valid loss = 1.4354530758730812
Update patience to 56.0
!!Model Saved with loss = 1.470967296304738,at 2019-12-06 22-05-23.

***** Epoch 28/50 *****
100/400-(0.000): Train nll PPL 3.999
200/400-(0.000): Train nll PPL 3.765
300/400-(0.000): Train nll PPL 3.811
0/400-(0.000): Train nll PPL 3.727
Checkpoint step at 2019-12-06 22-05-29
==== Evaluating Model ====
Train nll PPL 3.824
done epoch 28 -> 29
Generation: 50 batches
Val nll PPL 4.269
Total valid loss = 1.4512982432252806
Test nll PPL 4.168
Total valid loss = 1.4273453615464184
Update patience to 58.0
!!Model Saved with loss = 1.4512982432252806,at 2019-12-06 22-05-33.

***** Epoch 29/50 *****
100/400-(0.000): Train nll PPL 3.923
200/400-(0.000): Train nll PPL 3.738
300/400-(0.000): Train nll PPL 3.937
0/400-(0.000): Train nll PPL 3.586
Checkpoint step at 2019-12-06 22-05-39
==== Evaluating Model ====
Train nll PPL 3.793
done epoch 29 -> 30
Generation: 50 batches
Val nll PPL 4.259
Total valid loss = 1.4489177520424676
Test nll PPL 4.141
Total valid loss = 1.4209714953437051
!!Model Saved with loss = 1.4489177520424676,at 2019-12-06 22-05-43.

***** Epoch 30/50 *****
100/400-(0.000): Train nll PPL 3.671
200/400-(0.000): Train nll PPL 3.862
300/400-(0.000): Train nll PPL 3.798
0/400-(0.000): Train nll PPL 3.738
Checkpoint step at 2019-12-06 22-05-49
==== Evaluating Model ====
Train nll PPL 3.767
done epoch 30 -> 31
Generation: 50 batches
Val nll PPL 4.269
Total valid loss = 1.4513976602536727
Test nll PPL 4.130
Total valid loss = 1.4181902157036523

***** Epoch 31/50 *****
100/400-(0.000): Train nll PPL 3.839
200/400-(0.000): Train nll PPL 3.575
300/400-(0.000): Train nll PPL 3.644
0/400-(0.000): Train nll PPL 3.505
Checkpoint step at 2019-12-06 22-06-00
==== Evaluating Model ====
Train nll PPL 3.639
done epoch 31 -> 32
Generation: 50 batches
Val nll PPL 4.261
Total valid loss = 1.4495399048847466
Test nll PPL 4.128
Total valid loss = 1.4178172590161457

***** Epoch 32/50 *****
100/400-(0.000): Train nll PPL 3.639
200/400-(0.000): Train nll PPL 3.443
300/400-(0.000): Train nll PPL 3.430
0/400-(0.000): Train nll PPL 3.448
Checkpoint step at 2019-12-06 22-06-10
==== Evaluating Model ====
Train nll PPL 3.489
done epoch 32 -> 33
Generation: 50 batches
Val nll PPL 4.227
Total valid loss = 1.4415866204733339
Test nll PPL 4.122
Total valid loss = 1.4163371024249625
Update patience to 66.0
!!Model Saved with loss = 1.4415866204733339,at 2019-12-06 22-06-14.

***** Epoch 33/50 *****
100/400-(0.000): Train nll PPL 3.485
200/400-(0.000): Train nll PPL 3.381
300/400-(0.000): Train nll PPL 3.516
0/400-(0.000): Train nll PPL 3.568
Checkpoint step at 2019-12-06 22-06-20
==== Evaluating Model ====
Train nll PPL 3.487
done epoch 33 -> 34
Generation: 50 batches
Val nll PPL 4.216
Total valid loss = 1.4387881766826025
Test nll PPL 4.118
Total valid loss = 1.4153425938276283
!!Model Saved with loss = 1.4387881766826025,at 2019-12-06 22-06-24.

***** Epoch 34/50 *****
100/400-(0.000): Train nll PPL 3.497
200/400-(0.000): Train nll PPL 3.363
300/400-(0.000): Train nll PPL 3.354
0/400-(0.000): Train nll PPL 3.507
Checkpoint step at 2019-12-06 22-06-30
==== Evaluating Model ====
Train nll PPL 3.430
done epoch 34 -> 35
Generation: 50 batches
Val nll PPL 4.230
Total valid loss = 1.4423015942432784
Test nll PPL 4.115
Total valid loss = 1.4146310514823566

***** Epoch 35/50 *****
100/400-(0.000): Train nll PPL 3.535
200/400-(0.000): Train nll PPL 3.357
300/400-(0.000): Train nll PPL 3.411
0/400-(0.000): Train nll PPL 3.517
Checkpoint step at 2019-12-06 22-06-41
==== Evaluating Model ====
Train nll PPL 3.454
done epoch 35 -> 36
Generation: 50 batches
Val nll PPL 4.221
Total valid loss = 1.440064620267861
Test nll PPL 4.114
Total valid loss = 1.4143801075424078

***** Epoch 36/50 *****
100/400-(0.000): Train nll PPL 3.619
200/400-(0.000): Train nll PPL 3.465
300/400-(0.000): Train nll PPL 3.819
0/400-(0.000): Train nll PPL 3.536
Checkpoint step at 2019-12-06 22-06-51
==== Evaluating Model ====
Train nll PPL 3.607
done epoch 36 -> 37
Generation: 50 batches
Val nll PPL 4.219
Total valid loss = 1.4394859053551932
Test nll PPL 4.114
Total valid loss = 1.4143571327847673

***** Epoch 37/50 *****
100/400-(0.000): Train nll PPL 3.524
200/400-(0.000): Train nll PPL 3.561
300/400-(0.000): Train nll PPL 3.378
0/400-(0.000): Train nll PPL 3.487
Checkpoint step at 2019-12-06 22-07-01
==== Evaluating Model ====
Train nll PPL 3.487
done epoch 37 -> 38
Generation: 50 batches
Val nll PPL 4.211
Total valid loss = 1.4376582562703488
Test nll PPL 4.114
Total valid loss = 1.4143287283386115
!!Model Saved with loss = 1.4376582562703488,at 2019-12-06 22-07-05.

***** Epoch 38/50 *****
100/400-(0.000): Train nll PPL 3.500
200/400-(0.000): Train nll PPL 3.461
300/400-(0.000): Train nll PPL 3.405
0/400-(0.000): Train nll PPL 3.553
Checkpoint step at 2019-12-06 22-07-12
==== Evaluating Model ====
Train nll PPL 3.479
done epoch 38 -> 39
Generation: 50 batches
Val nll PPL 4.212
Total valid loss = 1.4380546469530056
Test nll PPL 4.114
Total valid loss = 1.4143164793574765

***** Epoch 39/50 *****
100/400-(0.000): Train nll PPL 3.301
200/400-(0.000): Train nll PPL 3.491
300/400-(0.000): Train nll PPL 3.494
0/400-(0.000): Train nll PPL 3.461
Checkpoint step at 2019-12-06 22-07-22
==== Evaluating Model ====
Train nll PPL 3.436
done epoch 39 -> 40
Generation: 50 batches
Val nll PPL 4.241
Total valid loss = 1.4446914541325446
Test nll PPL 4.113
Total valid loss = 1.4142742376817043

***** Epoch 40/50 *****
100/400-(0.000): Train nll PPL 3.412
200/400-(0.000): Train nll PPL 3.401
300/400-(0.000): Train nll PPL 3.690
0/400-(0.000): Train nll PPL 3.485
Checkpoint step at 2019-12-06 22-07-32
==== Evaluating Model ====
Train nll PPL 3.495
done epoch 40 -> 41
Generation: 50 batches
Val nll PPL 4.226
Total valid loss = 1.4412359991196777
Test nll PPL 4.113
Total valid loss = 1.414268693996473

***** Epoch 41/50 *****
100/400-(0.000): Train nll PPL 3.433
200/400-(0.000): Train nll PPL 3.551
300/400-(0.000): Train nll PPL 3.579
0/400-(0.000): Train nll PPL 3.445
Checkpoint step at 2019-12-06 22-07-43
==== Evaluating Model ====
Train nll PPL 3.502
done epoch 41 -> 42
Generation: 50 batches
Val nll PPL 4.236
Total valid loss = 1.4435682481505334
Test nll PPL 4.113
Total valid loss = 1.4142668154303113

***** Epoch 42/50 *****
100/400-(0.000): Train nll PPL 3.568
200/400-(0.000): Train nll PPL 3.450
300/400-(0.000): Train nll PPL 3.506
0/400-(0.000): Train nll PPL 3.608
Checkpoint step at 2019-12-06 22-07-53
==== Evaluating Model ====
Train nll PPL 3.532
done epoch 42 -> 43
Generation: 50 batches
Val nll PPL 4.213
Total valid loss = 1.4381243410585551
Test nll PPL 4.113
Total valid loss = 1.4142665429033707

***** Epoch 43/50 *****
100/400-(0.000): Train nll PPL 3.427
200/400-(0.000): Train nll PPL 3.363
300/400-(0.000): Train nll PPL 3.422
0/400-(0.000): Train nll PPL 3.720
Checkpoint step at 2019-12-06 22-08-03
==== Evaluating Model ====
Train nll PPL 3.480
done epoch 43 -> 44
Generation: 50 batches
Val nll PPL 4.227
Total valid loss = 1.4415471289870483
Test nll PPL 4.113
Total valid loss = 1.4142662716229153

***** Epoch 44/50 *****
100/400-(0.000): Train nll PPL 3.426
200/400-(0.000): Train nll PPL 3.495
300/400-(0.000): Train nll PPL 3.325
0/400-(0.000): Train nll PPL 3.363
Checkpoint step at 2019-12-06 22-08-13
==== Evaluating Model ====
Train nll PPL 3.402
done epoch 44 -> 45
Generation: 50 batches
Val nll PPL 4.235
Total valid loss = 1.4433150432206607
Test nll PPL 4.113
Total valid loss = 1.4142659825517196

***** Epoch 45/50 *****
100/400-(0.000): Train nll PPL 3.460
200/400-(0.000): Train nll PPL 3.470
300/400-(0.000): Train nll PPL 3.455
0/400-(0.000): Train nll PPL 3.387
Checkpoint step at 2019-12-06 22-08-24
==== Evaluating Model ====
Train nll PPL 3.443
done epoch 45 -> 46
Generation: 50 batches
Val nll PPL 4.226
Total valid loss = 1.4413735173725115
Test nll PPL 4.113
Total valid loss = 1.4142659085558396

***** Epoch 46/50 *****
100/400-(0.000): Train nll PPL 3.516
200/400-(0.000): Train nll PPL 3.578
300/400-(0.000): Train nll PPL 3.484
0/400-(0.000): Train nll PPL 3.469
Checkpoint step at 2019-12-06 22-08-34
==== Evaluating Model ====
Train nll PPL 3.512
done epoch 46 -> 47
Generation: 50 batches
Val nll PPL 4.226
Total valid loss = 1.441262862339231
Test nll PPL 4.113
Total valid loss = 1.4142655972745481

***** Epoch 47/50 *****
100/400-(0.000): Train nll PPL 3.632
200/400-(0.000): Train nll PPL 3.381
300/400-(0.000): Train nll PPL 3.473
0/400-(0.000): Train nll PPL 3.661
Checkpoint step at 2019-12-06 22-08-44
==== Evaluating Model ====
Train nll PPL 3.535
done epoch 47 -> 48
Generation: 50 batches
Val nll PPL 4.227
Total valid loss = 1.441479861296411
Test nll PPL 4.113
Total valid loss = 1.4142653615755727

***** Epoch 48/50 *****
100/400-(0.000): Train nll PPL 3.643
200/400-(0.000): Train nll PPL 3.295
300/400-(0.000): Train nll PPL 3.594
0/400-(0.000): Train nll PPL 3.373
Checkpoint step at 2019-12-06 22-08-54
==== Evaluating Model ====
Train nll PPL 3.473
done epoch 48 -> 49
Generation: 50 batches
Val nll PPL 4.222
Total valid loss = 1.4404072263363983
Test nll PPL 4.113
Total valid loss = 1.4142650930147207

***** Epoch 49/50 *****
100/400-(0.000): Train nll PPL 3.564
200/400-(0.000): Train nll PPL 3.418
300/400-(0.000): Train nll PPL 3.509
0/400-(0.000): Train nll PPL 3.462
Checkpoint step at 2019-12-06 22-09-04
==== Evaluating Model ====
Train nll PPL 3.488
done epoch 49 -> 50
Generation: 50 batches
Val nll PPL 4.260
Total valid loss = 1.4491879766277722
Test nll PPL 4.113
Total valid loss = 1.4142648619617346
Val nll PPL 4.260
Total valid loss = 1.449251467891285
Test nll PPL 4.114
Total valid loss = 1.4143287283386115
Generation: 263 batches
